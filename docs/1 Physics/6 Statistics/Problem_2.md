# Problem 2
Estimating Ï€ Using Monte Carlo Methods
Part 1: Estimating Ï€ Using a Circle
Theoretical Foundation
Consider a unit circle centered at the origin inscribed in a square with side length 2.

The area of the circle is 
ğœ‹
ğ‘Ÿ
2
=
ğœ‹
Ï€r 
2
 =Ï€ (since 
ğ‘Ÿ
=
1
r=1).

The area of the square is 
2
Ã—
2
=
4
2Ã—2=4.

Randomly generate points 
(
ğ‘¥
,
ğ‘¦
)
(x,y) uniformly in the square 
[
âˆ’
1
,
1
]
Ã—
[
âˆ’
1
,
1
]
[âˆ’1,1]Ã—[âˆ’1,1].

The probability that a point falls inside the circle is 
ğœ‹
4
4
Ï€
â€‹
 .

So, 
ğœ‹
â‰ˆ
4
Ã—
NumberÂ ofÂ pointsÂ insideÂ theÂ circle
TotalÂ points
Ï€â‰ˆ4Ã— 
TotalÂ points
NumberÂ ofÂ pointsÂ insideÂ theÂ circle
â€‹
 .

Python Simulation and Visualization
![alt text](image-3.png)
Analysis
Increasing num_points improves accuracy.

The method converges roughly at the rate 
1
ğ‘
N
â€‹
 
1
â€‹
  (slow).

Computationally cheap but noisy for small samples.

Part 2: Estimating Ï€ Using Buffonâ€™s Needle
Theoretical Foundation
Imagine parallel lines spaced distance 
ğ‘‘
d apart.

A needle of length 
ğ‘™
l is randomly dropped.

Probability 
ğ‘ƒ
P that the needle crosses a line is:

ğ‘ƒ
=
2
ğ‘™
ğœ‹
ğ‘‘
ifÂ 
ğ‘™
â‰¤
ğ‘‘
P= 
Ï€d
2l
â€‹
 ifÂ lâ‰¤d
Rearranging to estimate Ï€:

ğœ‹
â‰ˆ
2
ğ‘™
ğ‘
ğ‘‘
ğ¶
Ï€â‰ˆ 
dC
2lN
â€‹
 
where:

ğ‘
N = total needle drops,

ğ¶
C = number of crosses.

Python Simulation and Visualization
![alt text](image-4.png)
Analysis
The Buffon needle method often converges slower than the circle method.

More geometrically intuitive but requires care in implementation.

The crossing count can be zero for small samples â€” handle division carefully.

Comparison and Summary
Method	Convergence Speed	Complexity	Visual Intuition
Circle Monte Carlo	Moderate (
1
/
ğ‘
1/ 
N
â€‹
 )	Easy to implement	Clear, geometric
Buffonâ€™s Needle	Slower, more variable	More geometric reasoning	More abstract, line crossings

Both methods illustrate the power of Monte Carlo techniques for approximating constants.

